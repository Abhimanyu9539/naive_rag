{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047ab703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "import pinecone\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dca8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0daf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set up API keys from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize clients\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Index configuration\n",
    "INDEX_NAME = \"simple-rag-index\"\n",
    "DIMENSION = 1536  # OpenAI embeddings dimension\n",
    "\n",
    "print(\"Clients initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46612d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new index: simple-rag-index\n",
      "Connected to index: simple-rag-index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gen AI\\RAG_Projects\\naive_rag\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Create or connect to Pinecone index\n",
    "try:\n",
    "    # Try to create index if it doesn't exist\n",
    "    if INDEX_NAME not in [index.name for index in pc.list_indexes()]:\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=DIMENSION,\n",
    "            metric=\"cosine\", \n",
    "            spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-east-1\")\n",
    "        )\n",
    "        print(f\"Created new index: {INDEX_NAME}\")\n",
    "    else:\n",
    "        print(f\"Index {INDEX_NAME} already exists\")\n",
    "    \n",
    "    # Connect to the index\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    print(f\"Connected to index: {INDEX_NAME}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9e04d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks from 6 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample documents (replace with your own documents)\n",
    "documents = [\n",
    "    \"Artificial Intelligence is transforming the way we work and live. It includes machine learning, deep learning, and natural language processing.\",\n",
    "    \"Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to model and understand complex patterns in data.\",\n",
    "    \"Natural language processing (NLP) helps computers understand, interpret and generate human language in a valuable way.\",\n",
    "    \"Python is a popular programming language for AI and machine learning due to its simplicity and powerful libraries.\",\n",
    "    \"Data science involves extracting insights from structured and unstructured data using scientific methods and algorithms.\"\n",
    "]\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = []\n",
    "for i, doc in enumerate(documents):\n",
    "    doc_chunks = text_splitter.split_text(doc)\n",
    "    for j, chunk in enumerate(doc_chunks):\n",
    "        chunks.append({\n",
    "            \"id\": f\"doc_{i}_chunk_{j}\",\n",
    "            \"text\": chunk,\n",
    "            \"source\": f\"document_{i}\"\n",
    "        })\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d709de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored 6 vectors in Pinecone\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings and store in Pinecone\n",
    "embeddings_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Process chunks and store in Pinecone\n",
    "vectors_to_upsert = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    # Create embedding for the chunk\n",
    "    embedding = embeddings_model.embed_query(chunk[\"text\"])\n",
    "    \n",
    "    # Prepare vector for upsert\n",
    "    vector = {\n",
    "        \"id\": chunk[\"id\"],\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"source\": chunk[\"source\"]\n",
    "        }\n",
    "    }\n",
    "    vectors_to_upsert.append(vector)\n",
    "\n",
    "# Upsert vectors to Pinecone\n",
    "try:\n",
    "    index.upsert(vectors=vectors_to_upsert)\n",
    "    print(f\"Successfully stored {len(vectors_to_upsert)} vectors in Pinecone\")\n",
    "except Exception as e:\n",
    "    print(f\"Error storing vectors: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cl3igx1tm2q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG query function created successfully!\n"
     ]
    }
   ],
   "source": [
    "def simple_rag_query(question, top_k=3):\n",
    "    \"\"\"\n",
    "    Simple RAG function that retrieves relevant documents and generates an answer\n",
    "    \"\"\"\n",
    "    # Create embedding for the question\n",
    "    question_embedding = embeddings_model.embed_query(question)\n",
    "    \n",
    "    # Search for similar vectors in Pinecone\n",
    "    results = index.query(\n",
    "        vector=question_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Extract relevant context\n",
    "    context = \"\"\n",
    "    sources = []\n",
    "    for match in results.matches:\n",
    "        context += match.metadata[\"text\"] + \"\\n\\n\"\n",
    "        sources.append(match.metadata[\"source\"])\n",
    "    \n",
    "    # Generate response using OpenAI\n",
    "    prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Please answer the question based on the provided context. If the context doesn't contain enough information to answer the question, say so.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"sources\": list(set(sources)),\n",
    "            \"context_snippets\": [match.metadata[\"text\"] for match in results.matches]\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error generating response: {e}\"}\n",
    "\n",
    "print(\"RAG query function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1lp095tjq01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG System:\n",
      "==================================================\n",
      "\n",
      "Question: What is machine learning?\n",
      "Answer: Machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed.\n",
      "Sources: document_1, document_2, document_0\n",
      "------------------------------\n",
      "\n",
      "Question: How does deep learning work?\n",
      "Answer: Deep learning works by using neural networks with multiple layers to model and understand complex patterns in data. These networks are trained on large datasets to recognize patterns and make predictions or decisions based on the input data.\n",
      "Sources: document_1, document_2, document_0\n",
      "------------------------------\n",
      "\n",
      "Question: What programming language is good for AI?\n",
      "Answer: Python is a good programming language for AI, especially for machine learning and deep learning, due to its simplicity and powerful libraries. It is widely used in the field of artificial intelligence.\n",
      "Sources: document_0, document_1, document_4\n",
      "------------------------------\n",
      "\n",
      "Question: What is data science?\n",
      "Answer: Based on the provided context, data science involves extracting insights from structured and unstructured data using scientific methods and algorithms.\n",
      "Sources: document_1, document_2, document_5\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG system with example queries\n",
    "test_questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does deep learning work?\",\n",
    "    \"What programming language is good for AI?\",\n",
    "    \"What is data science?\"\n",
    "]\n",
    "\n",
    "print(\"Testing RAG System:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    result = simple_rag_query(question)\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"Sources: {', '.join(result['sources'])}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562f5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
